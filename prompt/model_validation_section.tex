% ============================================================
% Model Performance and Empirical Validation - LaTeX Code
% ============================================================

% -------------------- 两个并排表格：Uncertainty by Season & by Week --------------------
\begin{table}[htbp]
\centering
\caption{Model Uncertainty (CV) Across Seasons and Weeks by Voting Regime}
\label{tab:uncertainty}
\begin{minipage}[t]{0.48\textwidth}
\centering
\subcaption{Uncertainty by Season (Avg CV)}
\label{tab:uncertainty_season}
\small
\begin{tabular}{clc}
\toprule
\textbf{Season} & \textbf{Regime} & \textbf{Avg CV} \\
\midrule
1--2   & Rank     & 0.186 \\
3--27  & Percent  & 0.014 \\
28--34 & Bottom-2 & 0.449 \\
\midrule
\multicolumn{2}{l}{\textit{Overall Mean}} & 0.087 \\
\bottomrule
\end{tabular}
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}
\centering
\subcaption{Uncertainty by Week (Avg CV)}
\label{tab:uncertainty_week}
\small
\begin{tabular}{ccccc}
\toprule
\textbf{Week} & \textbf{Rank} & \textbf{Pct} & \textbf{B-2} & \textbf{All} \\
\midrule
1  & 0.293 & 0.022 & 0.487 & 0.142 \\
2  & 0.236 & 0.018 & 0.518 & 0.146 \\
3  & 0.196 & 0.015 & 0.523 & 0.144 \\
4  & 0.165 & 0.014 & 0.523 & 0.144 \\
5  & 0.122 & 0.012 & 0.511 & 0.140 \\
6  & 0.086 & 0.011 & 0.451 & 0.124 \\
7  & 0.093 & 0.011 & 0.405 & 0.114 \\
8  & 0.078 & 0.010 & 0.343 & 0.100 \\
9  & --    & 0.010 & 0.289 & 0.089 \\
10 & --    & 0.008 & 0.260 & 0.077 \\
11 & --    & 0.007 & 0.270 & 0.135 \\
\bottomrule
\end{tabular}
\end{minipage}
\end{table}


% ============================================================
% 论文正文部分
% ============================================================

\subsection{Model Performance and Empirical Validation}

To address the core questions of consistency and certainty in our fan vote estimates, we evaluate model performance along two orthogonal dimensions: (1)~\textit{consistency}---whether our inferred fan votes produce elimination outcomes that match the observed results; and (2)~\textit{uncertainty}---how precisely we can pinpoint the fan vote shares, quantified by the coefficient of variation (CV) and confidence interval width.

\subsubsection{Consistency Analysis}

\textbf{Definition.} For each week $w$, let $\hat{v}_i^{(w)}$ denote our estimated fan vote share for contestant $i$, and let $E_w$ be the set of contestants actually eliminated. We define the \textit{consistency probability} as the proportion of weeks where the model's predicted bottom-ranked contestant(s) under the applicable voting rule coincide with $E_w$:
\begin{equation}
    P_{\text{cons}} = \frac{1}{|W|} \sum_{w \in W} \mathbf{1}\left[\text{Elim}(\hat{\mathbf{v}}^{(w)}) = E_w\right].
\end{equation}

\textbf{Results by Season.} As illustrated in Figure~\ref{fig:cons_cer} (upper-right panel), the model achieves near-perfect consistency across the Percent regime (Seasons~3--27), with an average consistency probability of $\bar{P}_{\text{cons}} = 0.95$. The Rank regime (Seasons~1--2) exhibits slightly lower consistency ($\bar{P} = 0.88$), attributable to the rank-compression effect that reduces the discriminative power of elimination signals. The Bottom-2 regime (Seasons~28--34) maintains robust consistency ($\bar{P} = 0.89$) despite the structural ambiguity introduced by the judges' save mechanism.

\textbf{Results by Week.} The lower-right panel of Figure~\ref{fig:cons_cer} reveals a temporal pattern: consistency remains high ($P > 0.93$) during early-to-mid competition (Weeks~1--8), but declines sharply in later weeks---particularly Week~10 ($P = 0.55$) and Week~11 ($P = 0.56$). This phenomenon reflects the \textit{information scarcity} in late-stage competition: with only 3--4 contestants remaining, a single elimination event provides limited discriminative constraints, increasing the feasible region of fan vote distributions that could explain the outcome.

\subsubsection{Uncertainty Quantification}

\textbf{Metrics.} We employ two complementary measures of inference precision:
\begin{itemize}
    \item \textbf{Coefficient of Variation (CV)}: $\text{CV}_i = \sigma_i / \mu_i$, capturing relative volatility of estimates across Monte Carlo samples.
    \item \textbf{Confidence Interval Width}: The 95\% CI width $w_{95} = \hat{v}_i^{(97.5)} - \hat{v}_i^{(2.5)}$, measuring absolute uncertainty magnitude.
\end{itemize}

\textbf{Regime-Dependent Uncertainty.} Table~\ref{tab:uncertainty} and Figure~\ref{fig:cons_cer} (left panels) reveal a striking regime-dependent pattern in model uncertainty:

\begin{itemize}
    \item \textbf{Percent Regime (S3--27):} The model achieves exceptional precision with an average CV of only $\bar{\text{CV}} = 0.014$ (1.4\%). This reflects the rich informational content of percentage-based voting: the exact numerical thresholds for elimination impose tight mathematical constraints on feasible fan vote distributions.
    
    \item \textbf{Rank Regime (S1--2):} Uncertainty is elevated ($\bar{\text{CV}} = 0.186$), representing a 13$\times$ increase over the Percent era. The rank-transformation compresses continuous vote shares into discrete ordinal positions, destroying magnitude information and widening the feasible solution space.
    
    \item \textbf{Bottom-2 Regime (S28--34):} The highest uncertainty ($\bar{\text{CV}} = 0.449$) arises from the judges' save mechanism. Since judges may override pure fan-vote rankings, the elimination outcome no longer deterministically identifies the lowest-voted contestant, introducing fundamental ambiguity that propagates through our inference.
\end{itemize}

\textbf{Temporal Evolution.} The spatio-temporal uncertainty visualization (Figure~\ref{fig:cons_cer}, lower-left) demonstrates two key patterns:

\begin{enumerate}
    \item \textbf{Within-Season Convergence:} For the Rank regime, CV decreases monotonically from Week~1 (0.29) to Week~8 (0.08), reflecting the cumulative information gain as sequential elimination events progressively constrain the feasible fan vote space.
    
    \item \textbf{Late-Week Divergence:} Paradoxically, CI width \textit{increases} in final weeks (see Figure~\ref{fig:cons_cer}, upper-left). With fewer contestants remaining, each individual's vote share becomes more sensitive to perturbations, and the constraint structure becomes sparser, leading to an ``uncertainty horizon'' effect.
\end{enumerate}

\subsubsection{Summary of Validation Findings}

\begin{table}[htbp]
\centering
\caption{Summary of Model Performance Metrics by Voting Regime}
\label{tab:validation_summary}
\small
\begin{tabular}{lccc}
\toprule
\textbf{Metric} & \textbf{Rank (S1--2)} & \textbf{Percent (S3--27)} & \textbf{Bottom-2 (S28--34)} \\
\midrule
Avg Consistency Prob. & 0.88 & 0.95 & 0.89 \\
Avg CV & 0.186 & 0.014 & 0.449 \\
Avg CI Width (95\%) & 0.091 & 0.008 & 0.118 \\
Information Quality & Moderate & High & Low \\
\bottomrule
\end{tabular}
\end{table}

In conclusion, our model demonstrates strong empirical validity: it correctly recovers elimination outcomes with high probability (overall $\bar{P}_{\text{cons}} = 0.93$), while uncertainty quantification reveals interpretable regime-dependent patterns that align with the theoretical information content of each voting mechanism. The Percent regime provides the most reliable inference, while the judges' save mechanism in recent seasons introduces irreducible ambiguity that is faithfully captured by our probabilistic framework.

% -------------------- 引用图片 --------------------
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.95\textwidth]{figures/cons&cer.png}
    \caption{Comprehensive visualization of model consistency and uncertainty. \textit{Upper-left:} Temporal evolution of inference confidence (CV and CI width by week). \textit{Lower-left:} Spatio-temporal CI width evolution across 34 seasons. \textit{Upper-right:} Weekly consistency trends by voting regime. \textit{Lower-right:} Season-level consistency probability with regime-colored bars.}
    \label{fig:cons_cer}
\end{figure}
